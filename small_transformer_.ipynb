{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhdettrM4LDbDdIVHnH4GM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Narmathan56/Experiments-and-Practices/blob/main/small_transformer_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBfHTGUq_a7L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\")"
      ],
      "metadata": {
        "id": "OZFigKDH_t74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DataSet Creation\n",
        "here we create the vocab for took the vocab_size\n",
        "Note: we will create  the embedding layer in model. so vocab_size is important to create that and em"
      ],
      "metadata": {
        "id": "Rl_mrQpAAseg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab={'<pad>':0,\"1\":1,\"2\":2,\"3\":3,\"4\":4,\"5\":5,\"+\":6,\"=\":7}\n",
        "inv_vocab={v:k for k,v in vocab.items()}"
      ],
      "metadata": {
        "id": "nX14iatVAZvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[\n",
        "    ([1,6,1,7], [2]),\n",
        "    ([2,6,3,7], [5]),\n",
        "    ([3,6,4,7], [7]),\n",
        "]"
      ],
      "metadata": {
        "id": "Wb5QnjDlCFux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting to Tensor"
      ],
      "metadata": {
        "id": "OtpjdRJZCY6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=torch.tensor([x for x,_ in data], dtype=torch.long).to(device)\n",
        "y_train=torch.tensor([y for _,y in data],dtype=torch.long).to(device)\n"
      ],
      "metadata": {
        "id": "NjohZPlaCXG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tiny Transformer model"
      ],
      "metadata": {
        "id": "FIeaAO3EDZhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyTransformerModel(nn.module):\n",
        "  def__init__(self,vocab_size,embed_size=8,num_heads=2):\n",
        "    super().__init__()\n",
        "    self.empeddings=nn.Empedding(vocab_size,embed_size)\n",
        "    self.attn=nn.MultiheadAttention(embed_size=embed_size,num_heads=num_heads,batch_first=True)\n",
        "    self.fc=nn.linear(embed_size,vocab_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "6h3DGaqNDWj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating embeddings\n",
        "This is experimentation to how's look like embedding matrix through multiply the vocab_size and embed_size.\n",
        "Here vocab_size means total Number of unique token. it is fixed if we declare the token. but embed size resizable. so we can change the size but it should be power of 2 so number of heads will be divide if needed. how far we increase the embed size  as same as token information will be increased. efficiecy increased at the same time speed will decrease. so we have to choose the suitable embed size significantly impact the training process"
      ],
      "metadata": {
        "id": "Zm6nY0_bqWdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "vocab_size=8\n",
        "embed_size=8\n",
        "embeddings=nn.Embedding(vocab_size,embed_size)\n",
        "print(embeddings.weight[:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "RHTgVIXawBA-",
        "outputId": "c8adb727-fde7-4305-8476-d341d4a13723"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3414576934.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membed_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FIqIEmSoqTk5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}